{
    "nbformat_minor": 1, 
    "cells": [
        {
            "source": "## Criminal Justice Analytics\n### Applying the Data Science Methodology as an assessment to the practicality of analyzing, visualizing, and reporting on data as a method to describe crimes, diagnose scenarios that support criminal behavior, predict criminal activity, and prescribe scenarios that lower the probability of criminal activity.\n---\n#### Princeton Brooke\n###### Data Scientist and Cyber Security Software Engineer\n###### Website & Software Engineering Incorporated, Cleveland, Ohio\n\n###### Sunday, November 18, 2018\n###### This report is published for the IBM Data Science Professional Certification Coursera Program\n", 
            "cell_type": "markdown", 
            "metadata": {
                "collapsed": true
            }
        }, 
        {
            "source": "## Executive Summary\n#### By applying the data science methodology to the field of criminal justice - we can attempt to use descriptive analytics to answer what crimes have occurred, diagnostic analytics to answer why did a crime occur, predictive analytics to gain insights for what crimes might occur, and prescriptive analytics to answer the question of how to re-enact or possibly make the crime occur again.\n#### The data science methodology can be used to aid crime fighters. Businesses have used analytics for decades in order to gain competitive advantage. Manufacturers are using analytics to predict when robotic machines will fail, decrease assembly-line downtime, and anticipate maintenance requests. By collecting the right data, applying statistical algorithms to visualize and build models, and delivering actionable reporting dashboards - crime fighters can be more effective at anticipating criminal behavior, stopping crimes before they happen, lessening the impact of crimes, improving response times, or recovering after crimes occur.\n\n---\n## Literature Review\n#### A notable proponent of applying data science within the criminal justice realm is Anne Milgram. A TED Talks session was published on January 28, 2014 in which Anne addressed her passion of \u201cMoney Balling\u201d criminal justice. She explains that data can be used to reduce crimes and reallocate resources towards projects that improve public safety.\n#### At the time of her presentation statistics showed that there were 12 million arrests [per year] where 70-80% are low level crimes and less than 5% are attributed as violent crimes.\n#### 75-Billion dollars is spent on state and local corrections costs while 2.3 million people await in jail or prison. 2/3 are waiting for trial where they have not been convicted and there is a 67% recidivism rate which means 7/10 people are arrested multiple times.\n#### Highest risk offenders are being released because judges are not using data to drive decisions. Anne found that 5/10 criminal justice jurisdictions utilize analytics tools. The cost of implementing analytics projects is costly. A universal risk assessment tool was built that is easy to use. The tool can predict whether someone will commit a new crime upon release, predict if an act of violence will be committed, and predict whether a person will reappear in court.\n#### The data collected within the Public Safety Assessment Dashboard includes the following:\n#### Defendants biographical details, current offense type, whether the defendant was under the age of 21 or had pending charges at the time of offense, prior convictions such as misdemeanor, felony, violent, or sentenced to incarceration, and any prior failures to appear. A Pretrial Assessment Dashboard processes the data and displays a New Criminal Activity (NCA) Score and a Failure to Appear (FTA) Score.\n", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "## Data & Methodology\n#### This project will focus on data acquired from the city of Cleveland, Ohio. I will also gather geo-location data on the Pokemon Go Pokestop hubs within the Greater Cleveland region and use the Foursquare API to query social media checkin data.\n---\n#### Before we can begin to answer core questions on this topic, we must conduct analytical review. We must ask questions about crimes, criminal behaviors, and inquire about the data that is being collected. Is the data accessible and consistent? Does the data provide enough features to visualize a state that can clearly communicate ideas? Can the database be altered to improve to allow the collection of future features so that we can gain additional insights?\n#### This report seeks to examine criminal data collected from the city of Cleveland, Ohio and to determine if it correlates with geo-location check-ins from social media. We will compare the same crimes data with check-ins that are tagged with Pok\u00e9mon Pokestops to see if the outcomes shift or remain consistent. We will be using the FourSquare API, to acquire location-based data, and the Cleveland crimes data is published by the city of Cleveland.\n", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 28, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Fetching package metadata .............\nSolving package specifications: .\n\n# All requested packages already installed.\n# packages in environment at /opt/conda/envs/DSX-Python35:\n#\ngeopy                     1.17.0                     py_0    conda-forge\nFetching package metadata .............\nSolving package specifications: .\n\n# All requested packages already installed.\n# packages in environment at /opt/conda/envs/DSX-Python35:\n#\nfolium                    0.5.0                      py_0    conda-forge\nFolium installed\nLibraries imported.\n"
                }
            ], 
            "source": "!conda install -c conda-forge geopy --yes \nfrom geopy.geocoders import Nominatim # module to convert an address into latitude and longitude values\nimport requests # library to handle requests\n\nimport pandas as pd # library for data analsysis\npd.set_option(\"display.max_columns\", None)\n\nimport numpy as np # library to handle data in a vectorized manner\nimport re # import library for regular expression\nimport random # library for random number generation\n\n# libraries for displaying images\nfrom IPython.display import Image \nfrom IPython.core.display import HTML \n    \n# tranforming json file into a pandas dataframe library\nfrom pandas.io.json import json_normalize\n\n!conda install -c conda-forge folium=0.5.0 --yes\nimport folium # plotting library\n\nprint('Folium installed')\nprint('Libraries imported.')"
        }, 
        {
            "execution_count": 40, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "                            AGENCY NAME  POPULATION  VIOLENT CRIME  \\\n0                                   NaN         NaN            NaN   \n1  OHIO DEPARTMENT OF NATURAL RESOURCES         NaN            2.0   \n2             OHIO STATE HGHWAY PATROL          NaN          291.0   \n3                                 TOTAL         NaN          293.0   \n4                                   NaN         NaN            NaN   \n\n   PROPERTY CRIME  MURDER  RAPE  ROBBERY  AGGRAVATED ASSAULT  BURGLARY  \\\n0             NaN     NaN   NaN      NaN                 NaN       NaN   \n1            17.0     NaN   NaN      1.0                 1.0       2.0   \n2           233.0     1.0  35.0      4.0               251.0      12.0   \n3           250.0     1.0  35.0      5.0               252.0      14.0   \n4             NaN     NaN   NaN      NaN                 NaN       NaN   \n\n   LARCENY  MTR VEHICLE THEFT  ARSON  Unnamed: 12 Unnamed: 13  Unnamed: 14  \\\n0      NaN                NaN    NaN          NaN         NaN          NaN   \n1     15.0                NaN    1.0          NaN         NaN          NaN   \n2    179.0               42.0    2.0          NaN         NaN          NaN   \n3    194.0               42.0    3.0          NaN         NaN          NaN   \n4      NaN                NaN    NaN          NaN         NaN          NaN   \n\n   Unnamed: 15 Unnamed: 16  Unnamed: 17 Unnamed: 18  Unnamed: 19  Unnamed: 20  \\\n0          NaN         NaN          NaN         NaN          NaN          NaN   \n1          NaN         NaN          NaN         NaN          NaN          NaN   \n2          NaN         NaN          NaN         NaN          NaN          NaN   \n3          NaN         NaN          NaN         NaN          NaN          NaN   \n4          NaN         NaN          NaN         NaN          NaN          NaN   \n\n   Unnamed: 21  Unnamed: 22  Unnamed: 23  Unnamed: 24  Unnamed: 25  \\\n0          NaN          NaN          NaN          NaN          NaN   \n1          NaN          NaN          NaN          NaN          NaN   \n2          NaN          NaN          NaN          NaN          NaN   \n3          NaN          NaN          NaN          NaN          NaN   \n4          NaN          NaN          NaN          NaN          NaN   \n\n   Unnamed: 26  Unnamed: 27  Unnamed: 28  \n0          NaN          NaN          NaN  \n1          NaN          NaN          NaN  \n2          NaN          NaN          NaN  \n3          NaN          NaN          NaN  \n4          NaN          NaN          NaN  \n"
                }
            ], 
            "source": "# Cleveland Crimes Data\n\nfrom pandas import read_excel\nmy_sheet_name = 'Ohio Crime By County 2016' \ncleveland_crimes_df = read_excel('http://www.publicsafety.ohio.gov/links/ocjs-crime-by-county2016.xlsx', sheet_name = my_sheet_name)\nprint(cleveland_crimes_df.head()) # shows headers with top 5 rows\n"
        }, 
        {
            "execution_count": 41, 
            "cell_type": "code", 
            "metadata": {
                "scrolled": true
            }, 
            "outputs": [
                {
                    "execution_count": 41, 
                    "metadata": {}, 
                    "data": {
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>AGENCY NAME</th>\n      <th>Unnamed: 13</th>\n      <th>Unnamed: 16</th>\n      <th>Unnamed: 18</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>768</td>\n      <td>2</td>\n      <td>2</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>unique</th>\n      <td>710</td>\n      <td>1</td>\n      <td>2</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>top</th>\n      <td>SPRINGFIELD TOWNSHIP</td>\n      <td>12*</td>\n      <td>OH07609</td>\n      <td>MINERVA</td>\n    </tr>\n    <tr>\n      <th>freq</th>\n      <td>3</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>", 
                        "text/plain": "                 AGENCY NAME Unnamed: 13 Unnamed: 16 Unnamed: 18\ncount                    768           2           2           3\nunique                   710           1           2           3\ntop     SPRINGFIELD TOWNSHIP         12*     OH07609     MINERVA\nfreq                       3           2           1           1"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "cleveland_crimes_df.describe(include=['object'])"
        }, 
        {
            "execution_count": 42, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "execution_count": 42, 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "1.0        77\n2.0        42\n3.0        41\n6.0        27\n5.0        24\n4.0        23\n14.0       18\n7.0        15\n9.0        12\n11.0       12\n10.0       12\n13.0       10\n20.0       10\n17.0       10\n8.0         9\n24.0        9\n22.0        8\n15.0        8\n12.0        8\n45.0        7\n19.0        7\n16.0        6\n30.0        6\n32.0        6\n26.0        6\n75.0        5\n39.0        5\n27.0        5\n31.0        5\n29.0        5\n           ..\n107.0       1\n127.0       1\n87.0        1\n240.0       1\n91.0        1\n93.0        1\n2720.0      1\n200.0       1\n32703.0     1\n84.0        1\n254.0       1\n94.0        1\n120.0       1\n41.0        1\n46.0        1\n116.0       1\n99.0        1\n72.0        1\n108.0       1\n1072.0      1\n1216.0      1\n228.0       1\n58.0        1\n85.0        1\n585.0       1\n293.0       1\n218.0       1\n98.0        1\n460.0       1\n3463.0      1\nName: VIOLENT CRIME, Length: 134, dtype: int64"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "cleveland_crimes_df['VIOLENT CRIME'].value_counts()"
        }, 
        {
            "execution_count": 4, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# The code was removed by Watson Studio for sharing."
        }, 
        {
            "execution_count": 5, 
            "cell_type": "code", 
            "metadata": {
                "scrolled": true
            }, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stderr", 
                    "text": "/opt/conda/envs/DSX-Python35/lib/python3.5/site-packages/geopy/geocoders/osm.py:143: UserWarning: Using Nominatim with the default \"geopy/1.17.0\" `user_agent` is strongly discouraged, as it violates Nominatim's ToS https://operations.osmfoundation.org/policies/nominatim/ and may possibly cause 403 and 429 HTTP errors. Please specify a custom `user_agent` with `Nominatim(user_agent=\"my-application\")` or by overriding the default `user_agent`: `geopy.geocoders.options.default_user_agent = \"my-application\"`. In geopy 2.0 this will become an exception.\n  UserWarning\n"
                }, 
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "41.4969221 -81.6934307\n"
                }
            ], 
            "source": "# If the criminal database includes addresses we can attempt to use the code within this cell\n\naddress = '230 W Huron Rd, Cleveland, OH 44113'\n\ngeolocator = Nominatim()\nlocation = geolocator.geocode(address)\nlatitude = location.latitude\nlongitude = location.longitude\nprint(latitude, longitude)"
        }, 
        {
            "execution_count": 20, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# Our data provided by the city of Cleveland only includes county level name so we will manually provide location\nlatitude = 41.43\nlongitude = -81.67"
        }, 
        {
            "source": "## 1. FourSquare API Call\n> `https://api.foursquare.com/v2/venues/`**search**`?client_id=`**CLIENT_ID**`&client_secret=`**CLIENT_SECRET**`&ll=`**LATITUDE**`,`**LONGITUDE**`&v=`**VERSION**`&query=`**QUERY**`&radius=`**RADIUS**`&limit=`**LIMIT**", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 23, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "search_query = 'pokestop'\nradius = 500\nurl = 'https://api.foursquare.com/v2/venues/search?client_id={}&client_secret={}&ll={},{}&v={}&query={}&radius={}&limit={}'.format(CLIENT_ID, CLIENT_SECRET, latitude, longitude, VERSION, search_query, radius, LIMIT)"
        }, 
        {
            "execution_count": 24, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "execution_count": 24, 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "{'meta': {'code': 200, 'requestId': '5bf25a03351e3d0bc3b1fd2b'},\n 'response': {'venues': []}}"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "results = requests.get(url).json()\nresults"
        }, 
        {
            "execution_count": 25, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "execution_count": 25, 
                    "metadata": {}, 
                    "data": {
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table>\n</div>", 
                        "text/plain": "Empty DataFrame\nColumns: []\nIndex: []"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "# assign relevant part of JSON to venues\nvenues = results['response']['venues']\n\n# tranform venues into a dataframe\ndataframe = json_normalize(venues)\ndataframe.head()"
        }, 
        {
            "execution_count": 26, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "ename": "KeyError", 
                    "evalue": "\"None of [['name', 'categories', 'id']] are in the [columns]\"", 
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m", 
                        "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)", 
                        "\u001b[0;32m<ipython-input-26-f3f0320f5277>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# keep only columns that include venue name, and anything that is associated with location\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mfiltered_columns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'categories'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'location.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdataframe_filtered\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiltered_columns\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# function that extracts the category of the venue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", 
                        "\u001b[0;32m/opt/conda/envs/DSX-Python35/lib/python3.5/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1365\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mKeyError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1366\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1367\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1368\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1369\u001b[0m             \u001b[0;31m# we by definition only have the 0th axis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", 
                        "\u001b[0;32m/opt/conda/envs/DSX-Python35/lib/python3.5/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_tuple\u001b[0;34m(self, tup)\u001b[0m\n\u001b[1;32m    861\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m         \u001b[0;31m# no multi-index, so validate all of the indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 863\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_has_valid_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    864\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    865\u001b[0m         \u001b[0;31m# ugly hack for GH #836\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", 
                        "\u001b[0;32m/opt/conda/envs/DSX-Python35/lib/python3.5/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_has_valid_tuple\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    202\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mIndexingError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Too many indexers'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_has_valid_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m                 raise ValueError(\"Location based indexing can only have \"\n\u001b[1;32m    206\u001b[0m                                  \u001b[0;34m\"[{types}] types\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", 
                        "\u001b[0;32m/opt/conda/envs/DSX-Python35/lib/python3.5/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_has_valid_type\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1470\u001b[0m                         raise KeyError(\n\u001b[1;32m   1471\u001b[0m                             u\"None of [{key}] are in the [{axis}]\".format(\n\u001b[0;32m-> 1472\u001b[0;31m                                 key=key, axis=self.obj._get_axis_name(axis)))\n\u001b[0m\u001b[1;32m   1473\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n", 
                        "\u001b[0;31mKeyError\u001b[0m: \"None of [['name', 'categories', 'id']] are in the [columns]\""
                    ], 
                    "output_type": "error"
                }
            ], 
            "source": "# keep only columns that include venue name, and anything that is associated with location\nfiltered_columns = ['name', 'categories'] + [col for col in dataframe.columns if col.startswith('location.')] + ['id']\ndataframe_filtered = dataframe.loc[:, filtered_columns]\n\n# function that extracts the category of the venue\ndef get_category_type(row):\n    try:\n        categories_list = row['categories']\n    except:\n        categories_list = row['venue.categories']\n        \n    if len(categories_list) == 0:\n        return None\n    else:\n        return categories_list[0]['name']\n\n# filter the category for each row\ndataframe_filtered['categories'] = dataframe_filtered.apply(get_category_type, axis=1)\n\n# clean column names by keeping only last term\ndataframe_filtered.columns = [column.split('.')[-1] for column in dataframe_filtered.columns]\n\ndataframe_filtered"
        }, 
        {
            "execution_count": 27, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "ename": "NameError", 
                    "evalue": "name 'dataframe_filtered' is not defined", 
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m", 
                        "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)", 
                        "\u001b[0;32m<ipython-input-27-133796fd5c82>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Visualize the data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdataframe_filtered\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m", 
                        "\u001b[0;31mNameError\u001b[0m: name 'dataframe_filtered' is not defined"
                    ], 
                    "output_type": "error"
                }
            ], 
            "source": "# Visualize the data\ndataframe_filtered.name"
        }, 
        {
            "source": "---\n## Results\n#### The criminal justice system can use analytics to streamline processes and ultimately become more effective in the way crimes are analyzed. Judges can use data to make evidence-based decisions about the people seeking to be released from jail or prison.\n#### Due to my limited capacity to acquire enough data, the sources did not provide enough features to expand on the outcomes - at the time of this report. The city of Cleveland has not provided the public with the new database required to run deep analysis and is currently undergoing a revision to the way the city acquires and publishes its crimes database. There was data aggregated by county; however, in order to make a complete assessment of the crimes and to build a thorough understanding of how those crimes might relate to social media check-ins or to geo-location community-based games, such as Pok\u00e9mon Go, additional features would require time and date of crime along with location including latitude and longitude.\n#### A future assessment would require additional features based on Pok\u00e9mon Go. Collecting the latitude and longitude of every Pok\u00e9mon Pokestop and the Pok\u00e9mon Gyms would expand the research in several ways. This new dataset can be aggregated and clustered to visualize crimes per neighborhood, city, as well as at the county level.\n", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "---\n## Acknowledgements and References\n#### Case Western Reserve University\n###### ...........          Neocando \u2013 Neighborhood Data Warehouse\n###### ...........          Center on Urban Poverty and Community Development\n###### ...........          http://neocando.case.edu/neocando/\n\n#### FourSquare Developers API\n###### ...........          https://developer.foursquare.com/\n\n#### Getting Started with Data Science\n###### ...........          Murtaza Haider, IBM Press\n###### ...........          https://www.amazon.com/Getting-Started-Data-Science-Analytics/dp/0133991024\n\n#### US City Open Data Census\n###### ...........          http://us-city.census.okfn.org/dataset/crime-stats\n", 
            "cell_type": "markdown", 
            "metadata": {}
        }
    ], 
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.5", 
            "name": "python3", 
            "language": "python"
        }, 
        "language_info": {
            "mimetype": "text/x-python", 
            "nbconvert_exporter": "python", 
            "version": "3.5.5", 
            "name": "python", 
            "file_extension": ".py", 
            "pygments_lexer": "ipython3", 
            "codemirror_mode": {
                "version": 3, 
                "name": "ipython"
            }
        }
    }, 
    "nbformat": 4
}